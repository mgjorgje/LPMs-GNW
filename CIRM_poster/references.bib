@misc{Arias-Castro,
  doi = {10.48550/ARXIV.1804.10611},
  
  url = {https://arxiv.org/abs/1804.10611},
  
  author = {Arias-Castro, Ery and Channarond, Antoine and Pelletier, Bruno and Verzelen, Nicolas},
  
  keywords = {Statistics Theory (math.ST), Metric Geometry (math.MG), FOS: Mathematics, FOS: Mathematics},
  
  title = {On the Estimation of Latent Distances Using Graph Distances},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Snijders,
author = {Snijders, Tom and Nowicki, Krzysztof},
year = {1997},
month = {01},
pages = {75-100},
title = {Estimation and Prediction for Stochastic Blockmodels for Graphs with Latent Block Structure},
volume = {14},
journal = {Journal of Classification},
doi = {10.1007/s003579900004}
}


@article{Bollobas,
	doi = {10.1002/rsa.20168},
  
	url = {https://doi.org/10.1002%2Frsa.20168},
  
	year = 2007,
	publisher = {Wiley},
  
	volume = {31},
  
	number = {1},
  
	pages = {3--122},
  
	author = {B{\'{e}}la Bollob{\'{a}}s and Svante Janson and Oliver Riordan},
  
	title = {The phase transition in inhomogeneous random graphs},
  
	journal = {Random Structures and Algorithms}
}


@article{Integraloperators,
author = {Rosasco, Lorenzo and Belkin, Mikhail and De Vito, Ernesto},
year = {2010},
month = {02},
pages = {905-934},
title = {On Learning with Integral Operators},
volume = {11},
journal = {Journal of Machine Learning Research},
doi = {10.1145/1756006.1756036}
}                                           
@article{Tang,
	doi = {10.1214/13-aos1112},
  
	url = {https://doi.org/10.1214%2F13-aos1112},
  
	year = 2013,
	month = {06},
  
	publisher = {Institute of Mathematical Statistics},
  
	volume = {41},
  
	number = {3},
  
	author = {Minh Tang and Daniel L. Sussman and Carey E. Priebe},
  
	title = {Universally consistent vertex classification for latent positions graphs},
  
	journal = {The Annals of Statistics}
}

@article{Gine,
 ISSN = {13507265},
 URL = {http://www.jstor.org/stable/3318636},
 abstract = {Let $H\colon L_{2}(S,\scr{I},P)\mapsto L_{2}(S,\scr{I},P)$ be a compact integral operator with a symmetric kernel h. Let Xi, i∈ N, be independent S-valued random variables with common probability law P. Consider the n × n matrix H̃n with entries n-1h(Xi,Xj), 1 ≤ i, j ≤ n (this is the matrix of an empirical version of the operator H with P replaced by the empirical measure Pn), and let Hn denote the modification of H̃n, obtained by deleting its diagonal. It is proved that the l2 distance between the ordered spectrum of Hn and the ordered spectrum of H tends to zero a.s. if and only if H is Hilbert-Schmidt. Rates of convergence and distributional limit theorems for the difference between the ordered spectra of the operators Hn (or H̃n) and H are also obtained under somewhat stronger conditions. These results apply in particular to the kernels of certain functions H = φ(L) of partial differential operators L (heat kernels, Green functions).},
 author = {Vladimir Koltchinskii and Evarist Giné},
 journal = {Bernoulli},
 number = {1},
 pages = {113--167},
 publisher = {International Statistical Institute (ISI) and Bernoulli Society for Mathematical Statistics and Probability},
 title = {Random Matrix Approximation of Spectra of Integral Operators},
 urldate = {2022-06-01},
 volume = {6},
 year = {2000}
}

@article{Chatterjee,
	doi = {10.1214/14-aos1272},
  
	url = {https://doi.org/10.1214%2F14-aos1272},
  
	year = 2015,
	month = {02},
  
	publisher = {Institute of Mathematical Statistics},
  
	volume = {43},
  
	number = {1},
  
	author = {Sourav Chatterjee},
  
	title = {Matrix estimation by Universal Singular Value Thresholding},
  
	journal = {The Annals of Statistics}
}

@misc{Oliviera,
  doi = {10.48550/ARXIV.0911.0600},
  
  url = {https://arxiv.org/abs/0911.0600},
  
  author = {Oliveira, Roberto Imbuzeiro},
  
  keywords = {Combinatorics (math.CO), Probability (math.PR), FOS: Mathematics, FOS: Mathematics, 05C80;60B20},
  
  title = {Concentration of the adjacency matrix and of the Laplacian in random graphs with independent edges},
  
  publisher = {arXiv},
  
  year = {2009},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Bickel,
	doi = {10.1214/11-aos904},
  
	url = {https://doi.org/10.1214%2F11-aos904},
  
	year = 2011,
	month = {10},
  
	publisher = {Institute of Mathematical Statistics},
  
	volume = {39},
  
	number = {5},
  
	author = {Peter J. Bickel and Aiyou Chen and Elizaveta Levina},
  
	title = {The method of moments and degree distributions for network models},
  
	journal = {The Annals of Statistics}
}


@article{Albert,
	doi = {10.1103/revmodphys.74.47},
  
	url = {https://doi.org/10.1103%2Frevmodphys.74.47},
  
	year = 2002,
	month = {01},
  
	publisher = {American Physical Society ({APS})},
  
	volume = {74},
  
	number = {1},
  
	pages = {47--97},
  
	author = {R{\'{e}}ka Albert and Albert-L{\'{a}}szl{\'{o}} Barab{\'{a}}si},
  
	title = {Statistical mechanics of complex networks},
  
	journal = {Reviews of Modern Physics}
}
@book{Tsybakov,
author = {Tsybakov, Alexandre B.},
title = {Introduction to Nonparametric Estimation},
year = {2008},
isbn = {0387790519},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {This is a concise text developed from lecture notes and ready to be used for a course on the graduate level. The main idea is to introduce the fundamental concepts of the theory while maintaining the exposition suitable for a first approach in the field. Therefore, the results are not always given in the most general form but rather under assumptions that lead to shorter or more elegant proofs. The book has three chapters. Chapter 1 presents basic nonparametric regression and density estimators and analyzes their properties. Chapter 2 is devoted to a detailed treatment of minimax lower bounds. Chapter 3 develops more advanced topics: Pinskers theorem, oracle inequalities, Stein shrinkage, and sharp minimax adaptivity. This book will be useful for researchers and grad students interested in theoretical aspects of smoothing techniques. Many important and useful results on optimal and adaptive estimation are provided. As one of the leading mathematical statisticians working in nonparametrics, the author is an authority on the subject.}
}


@book{vershynin, place={Cambridge}, series={Cambridge Series in Statistical and Probabilistic Mathematics}, title={High-Dimensional Probability: An Introduction with Applications in Data Science}, DOI={10.1017/9781108231596}, publisher={Cambridge University Press}, author={Vershynin, Roman}, year={2018}, collection={Cambridge Series in Statistical and Probabilistic Mathematics}}


@article{Holland1983StochasticBF,
  title={Stochastic blockmodels: First steps},
  author={Paul Holland and Kathryn B. Laskey and Samuel Leinhardt},
  journal={Social Networks},
  year={1983},
  volume={5},
  pages={109-137}
}


@misc{Abbe,
  doi = {10.48550/ARXIV.1703.10146},
  
  url = {https://arxiv.org/abs/1703.10146},
  
  author = {Abbe, Emmanuel},
  
  keywords = {Probability (math.PR), Computational Complexity (cs.CC), Information Theory (cs.IT), Social and Information Networks (cs.SI), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Community Detection and Stochastic Block Models},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{Penrose2003RandomGG,
  title={Random Geometric Graphs},
  author={Mathew D. Penrose},
  year={2003}
}





@article{Hoff,
author = {Peter D Hoff and Adrian E Raftery and Mark S Handcock},
title = {Latent Space Approaches to Social Network Analysis},
journal = {Journal of the American Statistical Association},
volume = {97},
number = {460},
pages = {1090-1098},
year  = {2002},
publisher = {Taylor & Francis},
doi = {10.1198/016214502388618906},

URL = { 
        https://doi.org/10.1198/016214502388618906
    
},
eprint = { 
        https://doi.org/10.1198/016214502388618906
    
}

}

@article{Lei_2015,
	doi = {10.1214/14-aos1274},
  
	url = {https://doi.org/10.1214%2F14-aos1274},
  
	year = 2015,
	month = {feb},
  
	publisher = {Institute of Mathematical Statistics},
  
	volume = {43},
  
	number = {1},
  
	author = {Jing Lei and Alessandro Rinaldo},
  
	title = {Consistency of spectral clustering in stochastic block models},
  
	journal = {The Annals of Statistics}
}
@misc{Levina-Vershynin,
  doi = {10.48550/ARXIV.1502.03049},
  
  url = {https://arxiv.org/abs/1502.03049},
  
  author = {Le, Can M. and Levina, Elizaveta and Vershynin, Roman},
  
  keywords = {Statistics Theory (math.ST), Social and Information Networks (cs.SI), Probability (math.PR), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences, 05C80, 05C85, 60B20, 62H30},
  
  title = {Sparse random graphs: regularization and concentration of the Laplacian},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@book{Stein:1385521,
      author        = "Stein, Elias M and Shakarchi, Rami",
      title         = "{Real analysis: measure theory, integration, and Hilbert
                       spaces}",
      publisher     = "Princeton Univ. Press",
      address       = "Princeton, NJ",
      series        = "Princeton lectures in analysis",
      year          = "2005",
      url           = "https://cds.cern.ch/record/1385521",
}

@misc{Joan_bruna,
  doi = {10.48550/ARXIV.1705.08415},
  
  url = {https://arxiv.org/abs/1705.08415},
  
  author = {Chen, Zhengdao and Li, Xiang and Bruna, Joan},
  
  keywords = {Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Supervised Community Detection with Line Graph Neural Networks},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Wang,
author = {Wang, Hongwei and Zhang, Fuzheng and Zhang, Mengdi and Leskovec, Jure and Zhao, Miao and Li, Wenjie and Wang, Zhongyuan},
year = {2019},
month = {07},
pages = {968-977},
title = {Knowledge-aware Graph Neural Networks with Label Smoothness Regularization for Recommender Systems},
isbn = {978-1-4503-6201-6},
doi = {10.1145/3292500.3330836}
}

@misc{Gilmer,
  doi = {10.48550/ARXIV.1704.01212},
  
  url = {https://arxiv.org/abs/1704.01212},
  
  author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.6},
  
  title = {Neural Message Passing for Quantum Chemistry},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{devroye,
 ISSN = {03195724},
 URL = {http://www.jstor.org/stable/3315046},
 abstract = {If (X1,Y1),...,(Xn,Yn) is a sequence of independent identically distributed Rd× R-valued random vectors then Nadaraya (1964) and Watson (1964) proposed to estimate the regression function m(x)=E{Y1|X1=x} by mn(x)=∑i=1 nYiK((x-Xi)/hn)/∑i=1 nK((x-Xi))/hn), where K is a known density and {hn} is a sequence of positive numbers satisfying certain properties. In this paper a variety of conditions are given for the strong convergence to 0 of essX sup|mn(X)-m(X)| (here X is independent of the data and distributed as X1). The theorems are valid for all distributions of X1 and for all sequences {hn} satisfying hn→ 0 and nhn d/ log n→ ∞ . /// Soit (X1,Y1),...,(Xn,Yn) une suite de vecteurs aléatoires indépendants, identiquement distribués à valeurs dans Rd× R, Nadaraya (1964) et Watson (1964) ont proposé d'estimer la fonction de régression m(x)=E(Y1|X1=x) par mn(x)=∑i=1 nYiK((x-Xi)/hn)/∑i=1 nK((x-Xi))/hn), où K est une densité connue et {hn} est une suite de nombres positifs satisfaisant certaines hypothèses. Dans cet article, on présente plusieurs ensembles de conditions sous lesquelles essX sup|mn(X)-m(X)| converge fortement vers 0 (X est un vecteur aléatoire, indépendent des données ayant la même distribution que X1). Les théorèmes présentés sont vrais quelle que soit la distribution de X, et pour toutes les suites {hn} satisfaisant hn→ 0 et nhn d/ log n→ ∞ .},
 author = {Luc P. Devroye},
 journal = {The Canadian Journal of Statistics / La Revue Canadienne de Statistique},
 number = {2},
 pages = {179--191},
 publisher = {[Statistical Society of Canada, Wiley]},
 title = {The Uniform Convergence of the Nadaraya-Watson Regression Function Estimate},
 urldate = {2022-08-29},
 volume = {6},
 year = {1978}
}
